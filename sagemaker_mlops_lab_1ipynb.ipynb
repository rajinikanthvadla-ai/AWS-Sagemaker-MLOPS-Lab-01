{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8P7rnCsWhLpHVwIvRl6fN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajinikanthvadla-ai/AWS-Sagemaker-MLOPS-Lab-01/blob/main/sagemaker_mlops_lab_1ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F30OrqrwvPsp"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade pip setuptools wheel\n",
        "!pip install -q \"numpy==1.26.4\" \"pandas==2.1.4\" \"scikit-learn==1.3.2\" \"pyarrow==14.0.2\" \"sagemaker==2.224.0\" \"datasets==2.16.1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports and SageMaker Configuration\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import sagemaker\n",
        "from sagemaker import get_execution_role\n",
        "from datasets import load_dataset\n",
        "\n",
        "# SageMaker session and role setup\n",
        "sess = sagemaker.Session()\n",
        "region = sess.boto_region_name\n",
        "role = get_execution_role()\n",
        "\n",
        "bucket = \"sagemaker-hyd-house-rajini-2026\"\n",
        "prefix = \"hyd-house-price\"\n",
        "\n",
        "print(f\"Environment ready in {region}\")\n",
        "print(f\"Using Role: {role}\")"
      ],
      "metadata": {
        "id": "UgIfcNLj_XP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load and Clean Dataset\n",
        "# Load from Hugging Face\n",
        "ds = load_dataset(\"Saathwik56/houseprice\")\n",
        "df = ds[\"train\"].to_pandas()\n",
        "\n",
        "# Clean column names (lower case, remove spaces)\n",
        "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "\n",
        "print(f\"Dataset loaded with shape: {df.shape}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "vF_WdPX9_Zgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Data Cleaning and Splitting\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Identify target column\n",
        "target = \"price\" if \"price\" in df.columns else df.columns[-1]\n",
        "\n",
        "# Drop rows where target is missing\n",
        "df = df.dropna(subset=[target])\n",
        "\n",
        "# Clean numeric columns that are currently strings (like \"1,200,000\")\n",
        "for c in df.columns:\n",
        "    if df[c].dtype == \"object\":\n",
        "        # Remove commas and attempt conversion to numeric\n",
        "        temp_col = df[c].str.replace(\",\", \"\", regex=False)\n",
        "        df[c] = pd.to_numeric(temp_col, errors=\"ignore\")\n",
        "\n",
        "# Split the data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create local directory and save files\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "train_df.to_csv(\"data/train.csv\", index=False)\n",
        "test_df.to_csv(\"data/test.csv\", index=False)\n",
        "\n",
        "print(f\"Files saved locally: data/train.csv ({len(train_df)} rows), data/test.csv ({len(test_df)} rows)\")\n"
      ],
      "metadata": {
        "id": "qhZZXqmv_bZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Upload to S3\n",
        "train_path = sess.upload_data(path=\"data/train.csv\", bucket=bucket, key_prefix=f\"{prefix}/train\")\n",
        "test_path = sess.upload_data(path=\"data/test.csv\", bucket=bucket, key_prefix=f\"{prefix}/test\")\n",
        "\n",
        "print(f\"Train data uploaded to: {train_path}\")\n",
        "print(f\"Test data uploaded to: {test_path}\")"
      ],
      "metadata": {
        "id": "senKpJJ9_eyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "import argparse\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Handle SageMaker Paths\n",
        "    # Using environment variables is the 'best practice' way for SageMaker\n",
        "    train_dir = os.environ.get(\"SM_CHANNEL_TRAIN\", \"/opt/ml/input/data/train\")\n",
        "    model_dir = os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\")\n",
        "\n",
        "    # 2. Load Data\n",
        "    train_path = os.path.join(train_dir, \"train.csv\")\n",
        "    df = pd.read_csv(train_path)\n",
        "\n",
        "    # 3. Identify Target and Features\n",
        "    target = \"price\" if \"price\" in df.columns else df.columns[-1]\n",
        "\n",
        "    # Random Forest only accepts numbers.\n",
        "    # We drop columns that are still objects (text) for a quick fix.\n",
        "    X = df.drop(columns=[target]).select_dtypes(include=['number'])\n",
        "    y = df[target]\n",
        "\n",
        "    print(f\"Training with features: {list(X.columns)}\")\n",
        "\n",
        "    # 4. Train Model\n",
        "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # 5. Save Model\n",
        "    # SageMaker automatically picks up anything in model_dir and saves it to S3\n",
        "    joblib.dump(model, os.path.join(model_dir, \"model.joblib\"))\n",
        "    print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "rbQTohYz_gyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# --- Training Logic ---\n",
        "if __name__ == \"__main__\":\n",
        "    train_dir = os.environ.get(\"SM_CHANNEL_TRAIN\", \"/opt/ml/input/data/train\")\n",
        "    model_dir = os.environ.get(\"SM_MODEL_DIR\", \"/opt/ml/model\")\n",
        "\n",
        "    train_path = os.path.join(train_dir, \"train.csv\")\n",
        "    df = pd.read_csv(train_path)\n",
        "\n",
        "    target = \"price\" if \"price\" in df.columns else df.columns[-1]\n",
        "    X = df.drop(columns=[target]).select_dtypes(include=['number'])\n",
        "    y = df[target]\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    joblib.dump(model, os.path.join(model_dir, \"model.joblib\"))\n",
        "\n",
        "# --- Inference Logic (REQUIRED for Deployment) ---\n",
        "def model_fn(model_dir):\n",
        "    \"\"\"Load the model from the model_dir\"\"\"\n",
        "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
        "    return model"
      ],
      "metadata": {
        "id": "weHAnF3Z_jaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.sklearn.estimator import SKLearn\n",
        "\n",
        "# We use the path where we uploaded the training data in Cell 5\n",
        "# If you used 'train_path' in the previous cell, we use that here\n",
        "estimator = SKLearn(\n",
        "    entry_point=\"train.py\",\n",
        "    role=role,\n",
        "    instance_count=1,\n",
        "    instance_type=\"ml.m5.large\",\n",
        "    framework_version=\"1.2-1\",\n",
        "    base_job_name=\"hyd-house-training\",\n",
        "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
        "    py_version=\"py3\"\n",
        ")\n",
        "\n",
        "# Launching the job\n",
        "# Note: 'train_path' was defined in Cell 5 during the S3 upload\n",
        "estimator.fit({\"train\": train_path})"
      ],
      "metadata": {
        "id": "iUMWEwGL_nGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "sm = boto3.client('sagemaker')\n",
        "sm.delete_endpoint(EndpointName='hyd-house-endpoint')"
      ],
      "metadata": {
        "id": "a15AhiqF_pb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Deploy the model\n",
        "predictor = estimator.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=\"ml.t2.medium\", # You can also use \"ml.t2.medium\" for lower cost\n",
        "    endpoint_name=\"hyd-house-endpoint-rajini\"\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Success! ---\")\n",
        "print(f\"Endpoint Created: {predictor.endpoint_name}\")"
      ],
      "metadata": {
        "id": "IfK_x23Y_rMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Grab a sample row from your test data (excluding the target 'price')\n",
        "# We only take the numeric columns just like we did in train.py\n",
        "sample_data = test_df.select_dtypes(include=['number']).drop(columns=['price']).iloc[0:1]\n",
        "\n",
        "print(\"Sending features to endpoint:\")\n",
        "print(sample_data)\n",
        "\n",
        "# 2. Get prediction\n",
        "try:\n",
        "    prediction = predictor.predict(sample_data.values)\n",
        "\n",
        "    print(\"\\n--- Prediction Result ---\")\n",
        "    print(f\"Predicted House Price: {prediction[0]:,.2f}\")\n",
        "    print(f\"Actual House Price: {test_df['price'].iloc[0]:,.2f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction: {e}\")"
      ],
      "metadata": {
        "id": "9Vf3DjOY_tjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "# 1. Initialize the SageMaker client\n",
        "sm_client = boto3.client(\"sagemaker\")\n",
        "\n",
        "# 2. Define the name you used\n",
        "endpoint_name = \"hyd-house-endpoint-rajini\"\n",
        "\n",
        "try:\n",
        "    # Delete the endpoint\n",
        "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
        "    print(f\"Successfully deleted endpoint: {endpoint_name}\")\n",
        "\n",
        "    # Delete the endpoint configuration\n",
        "    sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
        "    print(f\"Successfully deleted endpoint configuration: {endpoint_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "rF6xwUdx_ugk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Delete the Model from SageMaker dashboard\n",
        "try:\n",
        "    # Note: The model name usually matches the training job name\n",
        "    # We can get it from the estimator we used earlier\n",
        "    model_name = estimator.latest_training_job.name\n",
        "    sm_client.delete_model(ModelName=model_name)\n",
        "    print(f\"Successfully deleted model: {model_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Model cleanup skipped or failed: {e}\")\n",
        "\n",
        "# 2. Remove local data folder\n",
        "import shutil\n",
        "if os.path.exists(\"data\"):\n",
        "    shutil.rmtree(\"data\")\n",
        "    print(\"Local 'data' folder removed.\")\n",
        "\n",
        "# 3. Remove the python script\n",
        "if os.path.exists(\"train.py\"):\n",
        "    os.remove(\"train.py\")\n",
        "    print(\"train.py removed.\")"
      ],
      "metadata": {
        "id": "POupbHG-_yvz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}